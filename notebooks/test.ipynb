{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7688e2d2-39de-4c46-aa41-6ee287a036b4",
   "metadata": {},
   "source": [
    "# Movie Recomendation systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e48a99-2607-4be5-98ca-aa69368180cf",
   "metadata": {},
   "source": [
    "It is a content based recomendation system that suggest or recommend moview to the user based on short description, keywords, title and actor names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16daf03-4e43-48c9-bd02-7d102b7bfb49",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c81f71f-75e7-4567-8d5d-586590d502f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a080f1de",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed545bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\palma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\palma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download stopwords and wordnet if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53ea7309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d0f795e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Movie recommendation system'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef6250b-cfd3-4ce2-aedc-82222f0889e1",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bebdbbb-cf10-4840-be90-e0a280fcd61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "\n",
    "df_credits = pd.read_csv('artifacts/raw/tmdb_5000_credits.csv')\n",
    "df_movies = pd.read_csv('artifacts/raw/tmdb_5000_movies.csv')\n",
    "\n",
    "df = df_movies.merge(df_credits, left_on='id', right_on='movie_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b18e456e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Batman raises the stakes in his war on crime. With the help of Lt. Jim Gordon and District Attorney Harvey Dent, Batman sets out to dismantle the remaining criminal organizations that plague the streets. The partnership proves to be effective, but they soon find themselves prey to a reign of chaos unleashed by a rising criminal mastermind known to the terrified citizens of Gotham as the Joker.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['original_title'] == 'The Dark Knight']['overview'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73f7a14e-03a1-41ce-a25a-5b88bd334002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['budget', 'genres', 'homepage', 'id', 'keywords', 'original_language',\n",
       "       'original_title', 'overview', 'popularity', 'production_companies',\n",
       "       'production_countries', 'release_date', 'revenue', 'runtime',\n",
       "       'spoken_languages', 'status', 'tagline', 'title_x', 'vote_average',\n",
       "       'vote_count', 'movie_id', 'title_y', 'cast', 'crew'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27eb75d1-77b3-43fa-bf05-1966d80dc779",
   "metadata": {},
   "source": [
    "Important columns\n",
    "\n",
    "1. id\n",
    "2. title\n",
    "3. overview\n",
    "4. genres\n",
    "5. cast\n",
    "6. crew\n",
    "7. keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a59d8ec-a148-47cd-a281-af52613b7d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\n",
    "\"id\",\n",
    "\"original_title\",\n",
    "\"overview\",\n",
    "\"genres\",\n",
    "\"cast\",\n",
    "\"crew\",\n",
    "\"keywords\"\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69146d5-8925-4e23-a67a-bd2f9121ed53",
   "metadata": {},
   "source": [
    "### Data cleaning and formating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "334dca95-b360-4045-b3fc-bb04e523a37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format genres column\n",
    "def convert_to_list(row):\n",
    "    l = []\n",
    "    for i in ast.literal_eval(row):\n",
    "        l.append(i['name'])\n",
    "    return ' '.join(l)\n",
    "df['genres'] = df['genres'].apply(convert_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fdd9b65-775b-4cb9-9fbe-efd6dca319d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format cast column\n",
    "def convert_to_list_cast(row):\n",
    "    l= []\n",
    "    flag = 0\n",
    "    for i in ast.literal_eval(row):\n",
    "        if flag == 5:\n",
    "            break\n",
    "        flag+=1\n",
    "        l.append(i['character'])\n",
    "        l.append(i['name'])\n",
    "    return ' '.join(l)\n",
    "df['cast'] = df['cast'].apply(convert_to_list_cast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b21a335d-f3ed-459c-8fc1-d3c5c0f573e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ast.literal_eval(df['crew'][0])\n",
    "# format crew column\n",
    "\n",
    "def convert_to_list_crew(row):\n",
    "    l = []\n",
    "    for i in ast.literal_eval(row):\n",
    "        if i['job'] == 'Director':\n",
    "            l.append(i['name'])\n",
    "            break\n",
    "    return ' '.join(l)\n",
    "df['crew'] = df['crew'].apply(convert_to_list_crew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66f6f18-cbf1-485c-9105-68e4734786d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "176de539-1e31-463c-98a6-4eccd5fcd138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kew=yword column formating\n",
    "df['keywords'] = df['keywords'].apply(convert_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e2a9f81-08dc-413f-b880-06de7ad45f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename({'original_title':'title'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b7e4956-fe20-4fd2-b4fd-ba2251847cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tags'] = df['title'] + df['overview'] + df['genres'] + df['cast'] + df['crew'] + df['keywords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a8f26f3-e0b5-44d5-85f5-a1e77eee3922",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df[['id', 'title', 'tags', 'overview', 'genres', 'crew']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77adef4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('artifacts/raw/movies.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adc2ff4-ef0a-4253-8074-64926e96e048",
   "metadata": {},
   "source": [
    "### Basic text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1c752f0e-119c-4f84-b8cd-3b78e4d24111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BasicTextPreprocessing:  \n",
    "    def __init__(self):  \n",
    "        pass \n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):  \n",
    "        \n",
    "        def keep_text_only(input_string):   \n",
    "            result = re.findall(r'[a-zA-Z\\s]+', input_string)   \n",
    "            return ''.join(result).strip()    \n",
    "        \n",
    "        def remove_urls(text):    \n",
    "            if isinstance(text, str):  # Check if the text is a string  \n",
    "                url_pattern = r'\\b(?:https?:\\/\\/)?(?:www\\.)?[a-zA-Z0-9-]+\\.[a-zA-Z]{2,}(?:\\/[^\\s]*)?\\b'    \n",
    "                cleaned_text = re.sub(url_pattern, '', text)   \n",
    "                return ' '.join(cleaned_text.split())  \n",
    "            return text  # Return as is for non-string inputs  \n",
    "            \n",
    "        def remove_punctuation(row):   \n",
    "            return row.translate(str.maketrans('', '', string.punctuation)) \n",
    "\n",
    "        def spell_correction(row):\n",
    "            l = []\n",
    "            for i in row.split():\n",
    "                l.append(str(TextBlob(i).correct()))\n",
    "            return ' '.join(l)\n",
    "            \n",
    "        def remove_stopwords(text):\n",
    "            stop_words = set(stopwords.words('english'))\n",
    "            return ' '.join([i for i in text.split() if i.lower() not in stop_words])\n",
    "\n",
    "        def lemmatization(row):  \n",
    "            lemmatizer = WordNetLemmatizer()\n",
    "            l = [lemmatizer.lemmatize(i) for i in row.split()]  \n",
    "            return ' '.join(l)\n",
    "            \n",
    "        X = X.str.lower()  \n",
    "        X = X.apply(keep_text_only)  \n",
    "        X = X.apply(remove_urls)  \n",
    "        X = X.apply(remove_punctuation)    \n",
    "        X = X.apply(remove_stopwords)  \n",
    "        X = X.apply(lemmatization)\n",
    "        return X.values\n",
    "        \n",
    "class CosineSimilarity:\n",
    "    def __init__(self):\n",
    "        return None\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return cosine_similarity(X)\n",
    "        \n",
    "# Creating pipeline\n",
    "tokenizer = Pipeline(steps=[\n",
    "    ('basic preprocessing', BasicTextPreprocessing()),\n",
    "    ('count vectorization', CountVectorizer(max_features=10000)),\n",
    "    ('tf-idf', TfidfTransformer())\n",
    "    # ('cosign similarity', CosineSimilarity())\n",
    "])\n",
    "\n",
    "# Assuming df is defined AttributeErrorand 'tags' is a column\n",
    "similarity = tokenizer.fit_transform(new_df['tags']).toarray() # Fixed for Series input\n",
    "\n",
    "def recommend(text):\n",
    "    a = tokenizer.transform(pd.Series([text]))\n",
    "    distances = np.dot(similarity, a.T).ravel()/(np.linalg.norm(similarity, axis=1)*(np.linalg.norm(a)))\n",
    "    top_movie_index = sorted(list(enumerate(distances)), reverse=True, key=lambda x: x[1])[1:6]\n",
    "    return top_movie_index\n",
    "recommend('a horror movie with love story and romance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c578cc21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.285162925720215 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Function to get file size\n",
    "def get_file_size(file_path):\n",
    "    file_size = os.path.getsize(file_path)\n",
    "    return file_size\n",
    "\n",
    "# Example usage\n",
    "file_path = 'artifacts/raw/movies.csv'\n",
    "file_size = get_file_size(file_path)\n",
    "print((file_size/1024)/1024, 'MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb5eeb9-4650-4fa4-8bb0-edec1afda49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(text):\n",
    "    a = tokenizer.transform(pd.Series([text]))\n",
    "    distances = np.dot(similarity, a.T).ravel()/(np.linalg.norm(similarity, axis=1)*(np.linalg.norm(a)))\n",
    "    top_movie_index = sorted(list(enumerate(distances)), reverse=True, key=lambda x: x[1])[1:6]\n",
    "    return top_movie_index\n",
    "recommend('a horror movie with love story and romance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d355584f-4fe6-43a7-bde1-abcd9a0c07e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'a horror love story movie'\n",
    "vector = tokenizer.transform(pd.Series([text]))\n",
    "a = vector.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "22fb463d-2936-4555-80d5-30a90a8fe2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4800, 10000), (1, 10000))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity.shape, a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7586406b-f53a-4075-a643-baa2b55835be",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = np.dot(similarity, a.T).ravel()/(np.linalg.norm(similarity, axis=1)*(np.linalg.norm(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "071962f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['title'] == 'The Dark Knight']['overview'].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "535c196f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 3, 4], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 2, 3, 4,5])\n",
    "np.where(a != 3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1d8c00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1769d85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adult': False,\n",
       " 'backdrop_path': '/1IWaKG7AWiYMhADxhGtnElDJAGI.jpg',\n",
       " 'belongs_to_collection': None,\n",
       " 'budget': 29000000,\n",
       " 'genres': [{'id': 878, 'name': 'Science Fiction'},\n",
       "  {'id': 53, 'name': 'Thriller'},\n",
       "  {'id': 9648, 'name': 'Mystery'}],\n",
       " 'homepage': '',\n",
       " 'id': 63,\n",
       " 'imdb_id': 'tt0114746',\n",
       " 'origin_country': ['US'],\n",
       " 'original_language': 'en',\n",
       " 'original_title': 'Twelve Monkeys',\n",
       " 'overview': \"In the year 2035, convict James Cole reluctantly volunteers to be sent back in time to discover the origin of a deadly virus that wiped out nearly all of the earth's population and forced the survivors into underground communities. But when Cole is mistakenly sent to 1990 instead of 1996, he's arrested and locked up in a mental hospital. There he meets psychiatrist Dr. Kathryn Railly, and patient Jeffrey Goines, the son of a famous virus expert, who may hold the key to the mysterious rogue group, the Army of the 12 Monkeys, thought to be responsible for unleashing the killer disease.\",\n",
       " 'popularity': 30.637,\n",
       " 'poster_path': '/gt3iyguaCIw8DpQZI1LIN5TohM2.jpg',\n",
       " 'production_companies': [{'id': 33,\n",
       "   'logo_path': '/8lvHyhjr8oUKOOy2dKXoALWKdp0.png',\n",
       "   'name': 'Universal Pictures',\n",
       "   'origin_country': 'US'},\n",
       "  {'id': 507,\n",
       "   'logo_path': '/aRmHe6GWxYMRCQljF75rn2B9Gv8.png',\n",
       "   'name': 'Atlas Entertainment',\n",
       "   'origin_country': 'US'},\n",
       "  {'id': 17031, 'logo_path': None, 'name': 'Classico', 'origin_country': ''},\n",
       "  {'id': 207976,\n",
       "   'logo_path': None,\n",
       "   'name': 'Twelve Monkeys Productions',\n",
       "   'origin_country': ''}],\n",
       " 'production_countries': [{'iso_3166_1': 'US',\n",
       "   'name': 'United States of America'}],\n",
       " 'release_date': '1995-12-29',\n",
       " 'revenue': 168841459,\n",
       " 'runtime': 129,\n",
       " 'spoken_languages': [{'english_name': 'English',\n",
       "   'iso_639_1': 'en',\n",
       "   'name': 'English'},\n",
       "  {'english_name': 'French', 'iso_639_1': 'fr', 'name': 'Français'}],\n",
       " 'status': 'Released',\n",
       " 'tagline': 'The future is history.',\n",
       " 'title': 'Twelve Monkeys',\n",
       " 'video': False,\n",
       " 'vote_average': 7.603,\n",
       " 'vote_count': 8223}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.themoviedb.org/3/movie/63?api_key=f5f0e091654432696b191938d11e63df\"\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer eyJhbGciOiJIUzI1NiJ9.eyJhdWQiOiJmNWYwZTA5MTY1NDQzMjY5NmIxOTE5MzhkMTFlNjNkZiIsIm5iZiI6MTcyNjY5ODEwOS4yNDczNTcsInN1YiI6IjY2ZWI0ZmE5NWMwNTE5YTIzNGQzYWRhYyIsInNjb3BlcyI6WyJhcGlfcmVhZCJdLCJ2ZXJzaW9uIjoxfQ.EzOK_WjEgmeL1GSbSUwH_9DLb8xvl-I_Ezp42LJyFw4\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dba1ea9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://image.tmdb.org/t/p/w500/gt3iyguaCIw8DpQZI1LIN5TohM2.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ast\n",
    "from IPython.display import Image, display\n",
    "\n",
    "image_url = 'https://image.tmdb.org/t/p/w500'+ response.json()['poster_path']\n",
    "\n",
    "image = Image(url=image_url)\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "186a8b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "https://image.tmdb.org/t/p/w500/hr0L2aueqlP2BYUblTTjmtn0hw4.jpg\n",
      "<Response [200]>\n",
      "https://image.tmdb.org/t/p/w500/4MpN4kIEqUjW8OPtOQJXlTdHiJV.jpg\n",
      "<Response [200]>\n",
      "https://image.tmdb.org/t/p/w500/rQRnQfUl3kfp78nCWq8Ks04vnq1.jpg\n",
      "<Response [200]>\n",
      "https://image.tmdb.org/t/p/w500/7fU5dSqKRL4XHeEUz62rCKBfYok.jpg\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "def fetch_movie_image(movie_id):\n",
    "    images_url = []\n",
    "    for id in movie_id:\n",
    "        url = f'https://api.themoviedb.org/3/movie/{id}?api_key=f5f0e091654432696b191938d11e63df'\n",
    "\n",
    "        headers = {\n",
    "            \"accept\": \"application/json\",\n",
    "            \"Authorization\": \"Bearer eyJhbGciOiJIUzI1NiJ9.eyJhdWQiOiJmNWYwZTA5MTY1NDQzMjY5NmIxOTE5MzhkMTFlNjNkZiIsIm5iZiI6MTcyNjY5ODEwOS4yNDczNTcsInN1YiI6IjY2ZWI0ZmE5NWMwNTE5YTIzNGQzYWRhYyIsInNjb3BlcyI6WyJhcGlfcmVhZCJdLCJ2ZXJzaW9uIjoxfQ.EzOK_WjEgmeL1GSbSUwH_9DLb8xvl-I_Ezp42LJyFw4\"\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, headers=headers)\n",
    "        print(response)\n",
    "        image_url = 'https://image.tmdb.org/t/p/w500'+ response.json()['poster_path']\n",
    "        print(image_url)\n",
    "        images_url.append(image_url)\n",
    "    return images_url\n",
    "url = fetch_movie_image([49026, 272, 102899, 855])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d5efbce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://image.tmdb.org/t/p/w500/zj8ongFhtWNsVlfjOGo8pSr7PQg.jpg',\n",
       " 'https://image.tmdb.org/t/p/w500/pFEtVPW88pWflYV84UFL0h1iJr3.jpg']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
